Num weight bits = 18
learning rate = 10
initial_t = 1
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/seq_small.cache
Reading from train-sets/seq_small
num sources = 1
average    since      sequence         example            current label      current predicted  current   cur   cur         predic.        examples
loss       last        counter          weight          sequence prefix        sequence prefix features  pass   pol            made          gener.
1.333333   1.333333          3        3.000000   [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]       18     2     0              18              12
1.000000   0.666667          6        6.000000   [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]       18     5     1              49              30
0.727273   0.400000         11       11.000000   [1 3 2 1 4 3         ] [1 3 2 1 4 3         ]       18    10     2             162              60

finished run
number of examples = 12
weighted example sum = 12
weighted label sum = 0
average loss = 0.6667
best constant = -0.09091
total feature number = 552
